---
title: "Estimação e interpretação de componentes de modelos mistos"
author: "Fernando Mayer"
date: "2018-06-22"
output:
  html_document:
    theme: flatly
    highlight: default
    code_folding: show
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
  pdf_document:
    toc: true
    toc_depth: 4
    number_sections: true
    highlight: "default"
documentclass: article
classoption: a4paper
fontsize: 10pt
geometry: margin=2.5cm
urlcolor: blue
header-includes:
  - \usepackage{amsmath}
  - \usepackage{mathpazo}
  #- \usepackage[scaled]{beramono}
  - \usepackage{inconsolata}
bibliography: ref.bib
---

```{r setup, cache=FALSE, include=FALSE}
source("setup_knitr.R")
## Tira a cache daqui
opts_chunk$set(cache = FALSE,
               out.width = "60%")
```

# Objetivos

Inicialmente entender como ajustar e interpretar os parâmetros e
componentes de variância de modelos mistos. Posteriormente, entender o
método de estimação dos parâmetros.

```{r}
## Pacotes necessários
library(tidyverse)
library(gridExtra)
```

# Definição do problema

Um modelo de regressão linear simples é definido por
$$
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \qquad i = 1, \ldots, n
$$
onde $n$ é número de indivíduos na amostra, e $\epsilon \sim \text{N}(0,
\sigma^2)$.

Agora suponha que os indivíduos na amostra possam ser separados (ou
classificados) em grupos diferentes, por exemplo, homens e mulheres.
Este agrupamento pode ajudar a explicar a variável resposta $Y$.

Uma forma (tradicional) de incorporar essa informação no modelo, é
adicionar essa variável classificadora como um fator no modelo. Isso
ajuda no ajuste, mas o número de parâmetros a serem esimados cresce
rapidamente. Para uma variável com $J$ categorias (níveis), o número de
parâmetros adicionais no modelo é $J-1$ (pois um nível estará no
intercepto). O objetivo é verificar se esse fator ajuda a explicar a
variabilidade em $Y$, e se existem diferenças entre seus níveis.

Uma outra forma de abordar esse problema é pensar que, ao invés de
estimar um parâmetro para cada nível de um fator para verificar se são
diferentes, podemos adicionar esse termo no modelo não como um fator,
mas como uma variável aleatória (VA) que ajuda a explicar parte da
variabilidade que antes estaria exclusicamente no erro $\epsilon$. Se
ele é uma VA, então possui uma distribuição de probabilidade. Com isso,
estariamos interessados em estimar o parâmetro de variância desta
distribuição de probabilidade. Uma variância estimada alta significa que
existe grande variabilidade entre os níveis daquele fator. Uma variância
baixa indica que os níveis tem valores próximos e que provavelmente esse
termo não seria útil no modelo (não ajuda a explicar a resposta). Note
que, dessa forma, aumentamos apenas um parâmetro no modelo (o parâmetro
de variância da distribuição atribuida a esse termo), ao invés de $J-1$
parâmetros.

De maneira bem geral, podemos redefinir o modelo tradicional para
incluir mais um termo de erro. Suponha que temos $i = 1, \ldots, n$
indivíduos classificados em $j = 1, \ldots, J$ grupos. Assim um possível
modelo seria
\begin{align*}
Y_{ij} &= \beta_0 + \beta_1 X_{ij} + b_j + \epsilon_i \\
  &= (\beta_0 + b_j) + \beta_1 X_{ij} + \epsilon_i
 \qquad i = 1, \ldots, n \text{ e } j = 1, \ldots, J
\end{align*}
onde $\epsilon_i \sim \text{N}(0, \sigma^2)$, e $b_j \sim \text{N}(0,
\sigma^2_b)$. Nesse caso, este é um modelo de intercepto aleatório, ou
seja, o parâmetro $\beta_1$ é o mesmo para todos os indivíduos, mas o
parâmetro $\beta_0$ será diferente para cada grupo $j$, pois $\beta_0 +
b_j \, \forall j$.

# Desenvolvimento

Suponha o seguinte modelo simulado:

```{r, out.width='80%'}
## Dados
set.seed(123)
n <- 1000
## Intercepto 1
b01 <- 10
b1 <- 0.5
x <- rnorm(n, mean = 150, sd = 15)
sigma2 <- 20
y <- b01 + b1*x + rnorm(n, mean = 0, sd = sqrt(sigma2))
## Intercepto 2
b02 <- -10
y2 <- b02 + b1*x + rnorm(n, mean = 0, sd = sqrt(sigma2))
## Junta os dados
da <- data.frame(x = c(x, x), y = c(y, y2),
                 gr = c(rep("A", length(y)), rep("B", length(y2))))
p1 <- ggplot(da, aes(x, y)) +
    geom_point(aes(colour = gr)) +
    geom_smooth(method = "lm", se = FALSE)
p2 <- ggplot(da, aes(x, y)) +
    geom_point(aes(colour = gr)) +
    facet_wrap(~ gr) +
    geom_smooth(method = "lm", se = FALSE)
grid.arrange(p1, p2, ncol = 2)
```

Claramente um modelo de regressão único para os dois grupos não é
adequado. Para comparação, podemos pensar nas seguintes alternativas:

1. Modelo naive (desconsiderando o grupo)
2. Modelo tradicional (grupo entra como fator)
3. Modelos separados (um para cada grupo)
4. Modelo de retas paralelas (diferentes interceptos, mesma inclinação)
5. Modelo com efeito aleatório

Ajustando cada um desses modelos:

1. Modelo naive (desconsiderando o grupo)

```{r}
## Modelo naive
m0 <- lm(y ~ x, data = da)
summary(m0)$coef
ggplot(da, aes(x, y)) +
    geom_point(aes(colour = gr)) +
    geom_smooth(method = "lm", se = FALSE)
```

2. Modelo tradicional (grupo entra como fator)

```{r}
## Modelo tradicional
m0t <- lm(y ~ x + gr, data = da, contrasts = list(gr = "contr.sum"))
summary(m0t)$coef
```

3. Modelos separados (um para cada grupo)

```{r}
## Por subset
m0a <- lm(y ~ x, data = da, subset = gr == "A")
summary(m0a)$coef
m0b <- lm(y ~ x, data = da, subset = gr == "B")
summary(m0b)$coef
ggplot(da, aes(x, y)) +
    geom_point(aes(colour = gr)) +
    geom_abline(slope = coef(m0a)[2], intercept = coef(m0a)[1]) +
    geom_abline(slope = coef(m0b)[2], intercept = coef(m0b)[1])
```

4. Modelo de retas paralelas (diferentes interceptos, mesma inclinação)

```{r}
## Modelo de retas paralelas
m0p <- lm(y ~ x + gr - 1, data = da)
summary(m0p)$coef
ggplot(da, aes(x, y)) +
    geom_point(aes(colour = gr)) +
    geom_abline(slope = coef(m0p)[1], intercept = coef(m0p)[2]) +
    geom_abline(slope = coef(m0p)[1], intercept = coef(m0p)[3])
```

5. Modelo com efeito aleatório

```{r}
## Modelo de efeito (intercepto) aleatório
library(lme4)
mm0 <- lmer(y ~ x + (1|gr), data = da)
summary(mm0)
```

Note que os coeficientes fixos estimados são idênticos aos do modelo
geral:

```{r}
coef(m0)
fixef(mm0)
```

No entanto, no modelo misto, temos o termo $b_j$, que representa os
desvios do intercepto comum para cada grupo. Estes desvios podem ser
obtidos com

```{r}
ranef(mm0)$gr
```

Ou seja, cada grupo possui intercepto dado por

```{r, echo=FALSE}
beta0 <- round(unname(fixef(mm0)[1]), 3)
b1 <- round(ranef(mm0)$gr[1,1], 3)
b2 <- round(ranef(mm0)$gr[2,1], 3)
sigma2b <- round(summary(mm0)$varcor$gr[1,1], 3)
```

\begin{align*}
\text{Grupo A:} \quad \beta_0 + b_1 &= `r beta0` + `r b1` = `r beta0+b1` \\
\text{Grupo B:} \quad \beta_0 + b_2 &= `r beta0` + `r b2` = `r beta0+b2`
\end{align*}

Isso pode ser visto com

```{r}
coef(mm0)
```

(*Como obter as estimativas dos efeitos aleatórios é algo que ainda
preciso ver*). Como assumimos que $b_j \sim \text{N}(0, \sigma^2_b)$,
temos que $\hat{\sigma}^2_b = `r sigma2b`$. Portanto, essa deve ser a
variância dos efeitos. De fato:

```{r}
mean(ranef(mm0)$gr[,1]) # média dos efeitos
var(ranef(mm0)$gr[,1])  # variância dos efeitos
```

Agora note que os parâmetros estimados com os efeitos aleatórios são
idênticos aos parâmetros estimados no modelo de retas paralelas, que
também é idêntico ao estimado no modelo tradicional:

```{r}
## Modelo de retas paralelas
coef(m0p)
## Modelo tradicional
coef(m0t)
coef(m0t)[1] + coef(m0t)[3] * c(1,-1)
## Modelo misto
coef(mm0)
```

E ainda que o erro padrão residual dos modelos de retas paralelas e
tradicionale  é igual ao erro padrão residual do modelo misto:

```{r}
summary(m0p)$sigma
summary(m0t)$sigma
sigma(mm0)
```

Issso significa que os três modelos são, na prática, equivalentes. No
entanto, duas distinções são importantes:

1. Embora nesse exemplo os três modelos tenham 4 parâmetros:
   ${\beta_0}_1$, ${\beta_0}_2$, $\beta_1$, $\sigma^2$ para os modelos
   tradicionais, e $\beta_0$, $\beta_1$, $\sigma^2$, $\sigma^2_b$, para
   o modelo misto, em qualquer outro caso onde o número de níveis do
   fator seja maior do que 2, o número de parâmetros dos modelos
   tradicionais irá aumentar. No caso dos modelos mistos, independente
   do número de níveis do fator, apenas um parâmetro (o de variância)
   precisará ser estimado.
2. A interpretação dos modelos de efeito fixo fica restrita aos níveis
   específicos daquele fator em estudo. Já no caso dos modelos mistos, a
   inferência pode ser generalizada para quaisquer outros níveis que
   existam para aquele fator, mesmo que não estejam presentes no modelo.
   Isso porque para que um fator seja considerado aleatório, já se
   pressupõe que seus níveis são uma amostra de todos os possíveis
   níveis de uma população.

Veja @Gelman2007.

# Algumas considerações

## Diferentes parametrizações no modelo tradicional

Se fizer o modelo tradicional com $X$ centrado na média, ou seja,
$$
Y_i = \beta_0 + \beta_1 (X_i - \bar{X}) + \epsilon_i, \qquad i = 1,
\ldots, n
$$
$\beta_0$ fica sendo a média geral do experimento. Nesse caso analisado
aqui (que é uma ANCOVA), o modelo centrado na média seria
$$
y_{ij} = \mu + \tau_i + \beta (x_{ij} - \bar{x}) + \epsilon_{ij}
$$
com $i = 1, \ldots, k$ grupos e $j = 1, \ldots, n$ observações. Dessa
forma, $\mu$ ficará sendo a média geral do experimento [@Montgomery2012,
pp. 657].Veja a diferença:

```{r}
## Modelo tradicional centrado na média
da$xc <- da$x - mean(da$x)
m0tc <- lm(y ~ xc + gr, data = da,
           contrasts = list(gr = "contr.sum"))
summary(m0tc)$coef
## Modelo tradicional
summary(m0t)$coef
## Média geral
mean(da$y)
```

Assim, a interpretação tradicional do modelo com restrição soma zero se
aplica, ou seja, o efeito estimado é a diferença entre a média geral e a
média de cada grupo

```{r}
mean(da$y)
## Média de cada grupo
with(da, tapply(y, gr, mean))
with(da, tapply(y, gr, mean)) - mean(da$y)
```

Ou, visto de outra forma, a média de cada grupo é a soma (subtração)
entre a média geral e o efeito estimado

```{r}
coef(m0tc)[1] - coef(m0tc)[3] * c(-1,1)
```

Considerando o modelo sem centrar na média, o $\mu$ não é mais a média
geral, e volta a ter a interpretação do intercepto em modelos de
regressão, e a média geral é obtida com
$$
\mu = \beta_0 + \beta_1 \bar{X}
$$
que é de fato
```{r}
coef(m0t)[1] + coef(m0t)[2]*mean(da$x)
```
Sendo assim, para calcular as médias de cada grupo, devemos considerar:
\begin{align*}
E[y_{1j}] = \mu_1 &= E[\mu + \tau_1 + \beta x_{1j}] \\
  &= \mu + \tau_1 + \beta \bar{x}_{1\bullet} \\
E[y_{2j}] = \mu_2 &= E[\mu - \tau_1 + \beta x_{2j}] \\
  &= \mu - \tau_1 + \beta \bar{x}_{2\bullet}
\end{align*}
que são
```{r}
## As médias dos grupos nesse caso são iguais
with(da, tapply(x, gr, mean))
xbarA <- mean(da$x[da$gr == "A"])
## Média do grupo A
coef(m0t)[1] + coef(m0t)[3] + coef(m0t)[2]*xbarA
## Média do grupo B
coef(m0t)[1] - coef(m0t)[3] + coef(m0t)[2]*xbarA
```
Da mesma forma, as estimativas dos efeitos podem ser obtidas isolando
$\tau_1$ nas equações acima
\begin{align*}
\hat{\tau_1} &= \mu_1 - \mu - \beta \bar{x}_{1\bullet} \\
 &= \mu + \beta \bar{x}_{2\bullet} - \mu_2
\end{align*}
Lembrando que $\mu = \beta_0$ nesse caso. Assim
```{r}
ybarA <- mean(da$y[da$gr == "A"])
ybarA - coef(m0t)[1] - coef(m0t)[2]*xbarA
ybarB <- mean(da$y[da$gr == "B"])
coef(m0t)[1] + coef(m0t)[2]*xbarA - ybarB
```
Ou, de maneira equivalente (somando as duas soluções)
\begin{align*}
2\hat{\tau_1} &= \mu_1 - \mu_2 + \beta \bar{x}_{2\bullet} -
  \beta \bar{x}_{1\bullet} \\
\hat{\tau_1} &= \frac{\mu_1 - \mu_2 +
  \beta (\bar{x}_{2\bullet} - \bar{x}_{1\bullet})}{2}
\end{align*}
ou seja
```{r}
(ybarA - ybarB + coef(m0t)[2]*(xbarA - xbarA))/2
```

## Obtenção dos componentes de variância pelo modelo tradicional

Já vimos que as estimativas dos efeitos fixos ($\beta_0$ e $\beta_1$)
são equivalentes nos modelos fixo e misto^[Modelo fixo aqui se refere ao
modelo tradicional com restrição soma zero, ajustado com a `lm()`.
Modelo misto é o modelo com intercepto aleatório (ou efeito de grupo),
como ajustado pela `lmer()`.].

Para a obtenção dos componentes de variância ($\sigma^2$ e
$\sigma^2_b$), a forma mais "tradicional" (ou antiga) de se obter suas
estimativas é através da própria análise de variância, utilizando o
**método dos momentos**. Outras formas são através dos métodos de máxima
verossimilhança e máxima verossimilhança restrita (REML) - como usado
pela **lme4** - e os métodos bayesianos. Uma observação importante é que
a obtenção dos componentes pela análise de variância, é sempre feita
considerando-se o modelo como fixo [@Barbin1993, pp. 8], e as
estimativas são obtidas posteriormente pelo método dos momentos.

As estimativas das variâncias através do método dos momentos são
relativamente simples. Basta lembrar que
\begin{align*}
E[QM_{trat}] &= \sigma^2 + n\sigma^2_b \\
E[QM_{res}] &= \sigma^2
\end{align*}
Agora basta igualar os valores observados e esperados e isolar os
componentes de interesse. Assim
\begin{align*}
\hat{\sigma}^2 &= QM_{res} \\
\hat{\sigma}^2_b &= \frac{QM_{trat} - \hat{\sigma}^2}{n} \\
  &= \frac{QM_{trat} - QM_{res}}{n}
\end{align*}
Portanto, pela tabela de ANOVA do modelo tradicional
```{r}
(an <- anova(m0t))
```
temos as seguintes estimativas
```{r}
## Estimativa de sigma^2
(QMres <- an[3,3])
## Estimativa de \sigma^2_b
(QMtrat <- an[2,3])
(QMtrat - QMres)/n
```
Note que o $n$ aqui é o número de repetições em cada grupo (nível),
portanto $n = `r n`$ (não é o número total de observações que seria
2000) [veja @Montgomery2012, pp. 118 para mais detalhes e
interpretação]. Note que esses são exatamente os mesmos resultados
obtidos pelo método da máxima verossimilhança restrita usando a `lmer()`
```{r}
print(VarCorr(mm0), comp = c("Variance", "Std.Dev."))
covs <- as.data.frame(VarCorr(mm0))
## Estimativa de sigma^2
covs[2,4]
## Estimativa de \sigma^2_b
covs[1,4]
```
isso porque o modelo é linear e normal, então os resultados devem ser os
mesmos.

# Referências online

- [Mixed model in simple
  english](https://stats.stackexchange.com/questions/55364/mixed-model-in-simple-english)
- [What is the difference between fixed effect, random effect and mixed
  effect models?](https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode)
- [What is a difference between random effects-, fixed effects- and
  marginal model?](https://stats.stackexchange.com/questions/21760/what-is-a-difference-between-random-effects-fixed-effects-and-marginal-model)
- [What's the interpretation of ranef, fixef, and coef in mixed effects
  model using lmer?](https://stats.stackexchange.com/questions/214129/whats-the-interpretation-of-ranef-fixef-and-coef-in-mixed-effects-model-using)
- [Understanding the variance of random effects in lmer() models](https://stats.stackexchange.com/questions/68106/understanding-the-variance-of-random-effects-in-lmer-models)
- [Why computing the variance of the extracted random effect (using
  ranef) is not the same as the output from lme?](https://stats.stackexchange.com/questions/69882/why-computing-the-variance-of-the-extracted-random-effect-using-ranef-is-not-t)
- [When should I *not* use R's nlm function for MLE?](https://stats.stackexchange.com/questions/9535/when-should-i-not-use-rs-nlm-function-for-mle)

# Referências
